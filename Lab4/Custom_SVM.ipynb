{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import functools\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(527, 40)\n",
      "First few data rows:\n",
      "[['D-1/3/90' 44101.0 1.5 7.8 nan]\n",
      " ['D-2/3/90' 39024.0 3.0 7.7 nan]\n",
      " ['D-4/3/90' 32229.0 5.0 7.6 nan]\n",
      " ['D-5/3/90' 35023.0 3.5 7.9 205.0]\n",
      " ['D-6/3/90' 36924.0 1.5 8.0 242.0]\n",
      " ['D-7/3/90' 38572.0 3.0 7.8 202.0]\n",
      " ['D-8/3/90' 41115.0 6.0 7.8 nan]\n",
      " ['D-9/3/90' 36107.0 5.0 7.7 215.0]\n",
      " ['D-11/3/90' 29156.0 2.5 7.7 206.0]\n",
      " ['D-12/3/90' 39246.0 2.0 7.8 172.0]]\n",
      "Num samples == 527\n",
      "Num features == 38\n"
     ]
    }
   ],
   "source": [
    "inputFile = \"water-treatmennt-original-marked.csv\"\n",
    "\n",
    "dataFrame = pd.read_csv(inputFile, header = 0, sep = ';')\n",
    "print(dataFrame.shape)\n",
    "data = dataFrame.values\n",
    "\n",
    "print(\"First few data rows:\")\n",
    "print(data[0:10, 0:5])\n",
    "\n",
    "numSamples = dataFrame.shape[0]\n",
    "print(\"Num samples == \" + str(numSamples))\n",
    "numFeatures = dataFrame.shape[1] - 2  #first feature is sampling date and last feature used as class marker\n",
    "print(\"Num features == \" + str(numFeatures))\n",
    "\n",
    "regularizationStrength = 10000\n",
    "learningRate = 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes: 13.0\n",
      "   Q-E      (input flow to plant)   ZN-E     (input Zinc to plant)\n",
      "0                         44101.0                              1.5\n",
      "1                         39024.0                              3.0\n",
      "2                         32229.0                              5.0\n",
      "3                         35023.0                              3.5\n",
      "4                         36924.0                              1.5\n",
      "5                         38572.0                              3.0\n",
      "6                         41115.0                              6.0\n",
      "7                         36107.0                              5.0\n",
      "8                         29156.0                              2.5\n",
      "9                         39246.0                              2.0\n",
      "          0         1\n",
      "0  0.680598  0.041916\n",
      "1  0.579121  0.086826\n",
      "2  0.443305  0.146707\n",
      "3  0.499151  0.101796\n",
      "4  0.537147  0.041916\n",
      "5  0.570087  0.086826\n",
      "6  0.620915  0.176647\n",
      "7  0.520817  0.146707\n",
      "8  0.381883  0.071856\n",
      "9  0.583558  0.056886\n"
     ]
    }
   ],
   "source": [
    "##########################################Removal of useless features#####################\n",
    "\n",
    "Y = dataFrame.iloc[:, -1]  # Class markers\n",
    "X = dataFrame.iloc[:, 1:-1]  # Features without date and class markers\n",
    "\n",
    "numClasses = np.amax(Y)\n",
    "print(\"Num classes: {0}\".format(numClasses))\n",
    "\n",
    "print(X.iloc[0:10, 0:2])\n",
    "\n",
    "##########################################Normalization#####################\n",
    "\n",
    "normalizedX = MinMaxScaler().fit_transform(X)\n",
    "X = pd.DataFrame(normalizedX)\n",
    "\n",
    "print(X.iloc[0:10, 0:2])\n",
    "\n",
    "##########################################Missing data handling#####################\n",
    "\n",
    "for sampleId in range(X.shape[0]):\n",
    "    for featureId in range(numFeatures):\n",
    "        if (math.isnan(X.iloc[sampleId, featureId])):\n",
    "            X.iloc[sampleId, featureId] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addFeatureForBias(data):\n",
    "    extendedData = np.zeros((data.shape[0], data.shape[1] + 1))\n",
    "    extendedData[:, 0:-1] = data\n",
    "    extendedData[:, -1] = int(1)\n",
    "    \n",
    "    return extendedData\n",
    "\n",
    "# test = pd.DataFrame([[0, 0],\n",
    "#                      [0, 0]])\n",
    "# print(addFeatureForBias(test))\n",
    "\n",
    "X = addFeatureForBias(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSoftMarginCost(weights, X, Y):\n",
    "    # Hinge loss\n",
    "    N = X.shape[0]\n",
    "    distances = 1 - Y * (np.dot(X, weights))\n",
    "    \n",
    "    print(\"Num samples: {0}\".format(X.shape[0]))\n",
    "    print(\"Num classification errors: {0}\".format(len(distances[distances < 0])))\n",
    "    \n",
    "    distances[distances < 0] = 0  # equivalent to max(0, distance)\n",
    "    \n",
    "    dangerousDistances = distances[distances < 1]\n",
    "    print(\"Num samples inside borders: {0}\".format(len(dangerousDistances[dangerousDistances > 0])))\n",
    "    \n",
    "    hinge_loss = regularizationStrength * (np.sum(distances) / N)\n",
    "    \n",
    "    # Soft margin cost function\n",
    "    cost = 1 / 2 * np.dot(weights, weights) + hinge_loss\n",
    "    return cost\n",
    "\n",
    "def computeCostFunctionGradient(weights, xBatch, yBatch):\n",
    "#     print(type(xBatch))\n",
    "#     print(type(yBatch))\n",
    "    \n",
    "    # In case of SGD\n",
    "    if (type(yBatch) != np.ndarray):\n",
    "        yBatch = np.array([yBatch])\n",
    "        xBatch = np.array([xBatch])\n",
    "        \n",
    "    distances = 1 - (yBatch * np.dot(xBatch, weights))\n",
    "    \n",
    "    weightsDelta = np.zeros(len(weights))\n",
    "    \n",
    "    for index, distance in enumerate(distances):\n",
    "        if (max(0, distance) == 0):\n",
    "            deltaI = weights\n",
    "        else:\n",
    "            deltaI = weights - (regularizationStrength * yBatch[index] * xBatch[index])\n",
    "            \n",
    "        weightsDelta += deltaI\n",
    "        \n",
    "    weightsDelta = weightsDelta / len(yBatch)\n",
    "    \n",
    "    return weightsDelta\n",
    "\n",
    "def stochasticGradientDescent(features, outputs):\n",
    "    maxEpochs = 1024\n",
    "    weights = np.zeros(features.shape[1])\n",
    "\n",
    "    prevCost = float(\"inf\")\n",
    "    convergenceThreshold = 0.01 #percents\n",
    "    \n",
    "    for epoch in range(maxEpochs): \n",
    "        # To prevent repeating update cycles\n",
    "        X, Y = shuffle(features, outputs)\n",
    "        \n",
    "        for ind, x in enumerate(X):\n",
    "            gradientAscent = computeCostFunctionGradient(weights, x, Y[ind])\n",
    "            weights = weights - (learningRate * gradientAscent)\n",
    "            \n",
    "        if ((epoch % 100 == 0) or (epoch >= maxEpochs - 1)):\n",
    "            cost = computeSoftMarginCost(weights, features, outputs)\n",
    "            print(\"Epoch is:{} and cost is: {}\".format(epoch, cost))\n",
    "            \n",
    "            if (abs(prevCost - cost) < convergenceThreshold * prevCost):\n",
    "                return weights\n",
    "            \n",
    "            prevCost = cost\n",
    "            \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training started...\n",
      "Num classification errors: 126\n",
      "Num samples inside borders: 69\n",
      "Num samples: 368\n",
      "Epoch is:0 and cost is: 8993.458591208804\n",
      "Num classification errors: 161\n",
      "Num samples inside borders: 128\n",
      "Num samples: 368\n",
      "Epoch is:100 and cost is: 5425.699930763443\n",
      "Num classification errors: 162\n",
      "Num samples inside borders: 126\n",
      "Num samples: 368\n",
      "Epoch is:200 and cost is: 5288.224206491394\n",
      "Num classification errors: 163\n",
      "Num samples inside borders: 121\n",
      "Num samples: 368\n",
      "Epoch is:300 and cost is: 5249.661323655799\n",
      "training finished.\n",
      "weights are: [-0.24127673  1.10670602  0.95850529 -0.49645541  2.13162346  3.48918998\n",
      " -2.55778208 -0.51755141  1.02912201  0.82615812 -0.30220422  2.24496249\n",
      " -2.01993904 -1.06362738  0.71813307  1.17227739 -1.98080051 -3.8025231\n",
      "  0.47165857 -1.0426812   1.26436769 -0.42553123  1.93476806 -1.8915434\n",
      " -0.78220174  0.77252156  1.38464262 -0.12188401 -0.36968091  2.51988422\n",
      "  1.09194234 -2.60541872 -0.22571434 -0.11713781  0.0531357  -0.66722472\n",
      "  0.55046649  0.23070247  2.38846474]\n"
     ]
    }
   ],
   "source": [
    "yFirstVsAll = list(map(lambda y: -1.0 if y == 1 else 1.0, Y))\n",
    "\n",
    "# print(yFirstVsAll)\n",
    "# print(type(X.values))\n",
    "# print(type(yFirstVsAll))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, yFirstVsAll, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"training started...\")\n",
    "W = stochasticGradientDescent(X_train, y_train)\n",
    "print(\"training finished.\")\n",
    "print(\"weights are: {}\".format(W))\n",
    "\n",
    "y_test_predicted = [0] * X_test.shape[0]\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    yp = np.sign(np.dot(W, X_test[i]))\n",
    "    y_test_predicted[i] = yp\n",
    "\n",
    "# print(\"accuracy on test dataset: {}\".format(accuracy_score(y_test, y_test_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
